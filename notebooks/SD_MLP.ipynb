{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Stance Detection Using Multi-Layer Perceptron\n",
        "\n",
        "\n",
        "`Multi-Layer Perceptron`  \n",
        "`AraStance Dataset`  \n",
        "`Stance Detection` `Arabic Language`\n",
        "\n",
        "---\n",
        "\n",
        "In this notebook, we rely on very simple multi-layer perceptron to classify the stances of the articles in the AraStance dataset. The dataset was introduced in the paper:  \n",
        "```\n",
        "AraStance: A Multi-Country and Multi-Domain Dataset of Arabic Stance Detection for Fact Checking.\n",
        "```\n",
        "The perceptron we experiment with is inspired by the paper:\n",
        "```\n",
        "A simple but tough-to-beat baseline for the Fake News Challenge stance detection task\n",
        "```"
      ],
      "metadata": {
        "id": "gnUIcjY2vnPC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Packages"
      ],
      "metadata": {
        "id": "0vG9MG_iIsXQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from utils import AraStanceData, load_stop_words, stance_to_int, evaluate"
      ],
      "metadata": {
        "id": "gd-hHPDWIsAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Raw data"
      ],
      "metadata": {
        "id": "rTozKiy7XCBG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Download the raw data:"
      ],
      "metadata": {
        "id": "m0AvWlXSXvhb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_LOdU9qxUXTL"
      },
      "outputs": [],
      "source": [
        "!wget https://github.com/Tariq60/arastance/archive/refs/heads/main.zip\n",
        "!unzip /content/main.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Let's start by reading the raw data:"
      ],
      "metadata": {
        "id": "y7Gkmr6iXqqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_train = AraStanceData(\"/content/arastance-main/data/train.jsonl\")\n",
        "raw_dev = AraStanceData(\"/content/arastance-main/data/dev.jsonl\")\n",
        "raw_test = AraStanceData(\"/content/arastance-main/data/test.jsonl\")\n",
        "\n",
        "print(f'# training instances: {len(raw_train.stances)}')\n",
        "print(f'# validation instances: {len(raw_dev.stances)}')\n",
        "print(f'# testing instances: {len(raw_test.stances)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDuTS7IiXGKv",
        "outputId": "a4711160-c9f9-451c-d33b-1e25cdc21d61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# training instances: 2848\n",
            "# validation instances: 569\n",
            "# testing instances: 646\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Let's see an instance from the data:"
      ],
      "metadata": {
        "id": "OlqFipRemE2W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "instance_no = 10\n",
        "print(f\"Claim text: {raw_train.claims[raw_train.article_claim[instance_no]]}\")\n",
        "print(f\"Article text: {raw_train.articles[instance_no]}\")\n",
        "print(f\"Stance: {raw_train.stances[instance_no]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Er2Pnn1kZkzo",
        "outputId": "a3ee575a-c471-4463-d3d8-bad43624ae6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Claim text: العثور على طلاسم سحرية على ستار الكعبة المشرفة\n",
            "Article text: نفت الرئاسة العامة لشؤون المسجد الحرام والمسجد النبوي، ما تردد عن وجود سحر وطلاسم في ثوب الكعبة، مؤكدة أن ما عثر عليه هو ورقة تركها أحد الزوار تضمنت أدعية ظنًا منه أنها ستجلب له الخير. وكان عدد من منسوبي الرئاسة العامة لشؤون المسجد الحرام والمسجد النبوي قد عثروا على ورقة صغيرة الحجم موضوعة بطريقة مريبة بين خيوط إطار ثوب الكعبة المشرفة السفلي، فيما رجح مغردون أنها تتضمن سحرًا أو طلاسم. وأكد مصدر بالرئاسة العامة لشؤون الحرمين في تصريحات صحافية أنه تم تلقي بلاغ من منسوبي صيانة الكسوة عن وجود ورقة في أحد إطارات الكعبة المشرفة مصاغة بطريقة مريبة بخيوط الكعبة، حيث بادرت إدارة الهيئة بالمسجد الحرام هذا البلاغ وتم أخذ هذه الورقة التي لم يتضح أن بها سحر . وكان مغردون قد تداولوا مقطع فيديو يظهر لحظة العثور على الورقة في ثوب الكعبة مرجحين أنها سحر، داعين إلى سرعة التحقيق في الأمر وكشف الحقائق للناس.\n",
            "Stance: Disagree\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Thus, the instances are triplets, Claim/Article/Stance.\n",
        "- Note that the original language of the data is Arabic."
      ],
      "metadata": {
        "id": "5rUqAjGonKLH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset"
      ],
      "metadata": {
        "id": "ht1i__sCiXzC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- First, we need to vectorize the data. To do so, we'll use tf-idf vectors to represent the instances:"
      ],
      "metadata": {
        "id": "eyi87p2gnAgW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# lim_unigram is the size of the vocabulary or\n",
        "# the top features ordered by term frequency across the corpus\n",
        "lim_unigram = 4000\n",
        "batch_size = 512"
      ],
      "metadata": {
        "id": "Qz_8Lc0tbyxD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk_stop_words, custom_stop_words = load_stop_words()\n",
        "stop_words = nltk_stop_words + custom_stop_words\n",
        "\n",
        "# to fit the vectorizer, we will only use the training data.\n",
        "# Now, concatenate the pairs claims/articles\n",
        "train_instances = [raw_train.claims[raw_train.article_claim[idx]] + \" \" + article \\\n",
        "                  for idx, article in enumerate(raw_train.articles)]\n",
        "\n",
        "# fit the vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=lim_unigram, stop_words=stop_words)\n",
        "tfidf_vectorizer = tfidf_vectorizer.fit(train_instances)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLNfshDGX_GK",
        "outputId": "f7b369d2-0e57-454b-f5e7-07c5c676f722"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Now the vectorizer is fitted, we can start vectorizing the data:"
      ],
      "metadata": {
        "id": "EBlV_jW-ohDn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we will use this function to vectorize the data using the fitted vectorizer\n",
        "def vectorize(data):\n",
        "  feature_vectors = []\n",
        "\n",
        "  for idx in range(len(data.articles)):\n",
        "    claim = data.claims[data.article_claim[idx]]\n",
        "    article = data.articles[idx]\n",
        "\n",
        "    # vectorize the pair into (lim_unigram,) sparse vectors each\n",
        "    claim_tfidf = tfidf_vectorizer.transform([claim]).toarray()\n",
        "    article_tfidf = tfidf_vectorizer.transform([article]).toarray()\n",
        "\n",
        "    # find the similarity between claim and article vectors\n",
        "    similarity = cosine_similarity(claim_tfidf, article_tfidf)\n",
        "\n",
        "    # append the vectors and the similarity to construct (2 * lim_unigram + 1) vector\n",
        "    feat_vec = np.squeeze(np.c_[claim_tfidf, article_tfidf, similarity])\n",
        "    feature_vectors.append(tf.constant(feat_vec))\n",
        "\n",
        "  return feature_vectors\n",
        "\n",
        "train_features = vectorize(raw_train)\n",
        "dev_features = vectorize(raw_dev)\n",
        "test_features = vectorize(raw_test)"
      ],
      "metadata": {
        "id": "1zuSm0MqYJnk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Let's see a vectorized instance from the training data:"
      ],
      "metadata": {
        "id": "n_2mV5G5pN5p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "instance_no = 10\n",
        "print(f'shape of each feature vector is: {train_features[instance_no].shape}')\n",
        "print(f'feature vectors are sparse: {train_features[instance_no]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GloXmNCacQM",
        "outputId": "ba6eec67-1620-47ae-edab-23cc71a728ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of each feature vector is: (8001,)\n",
            "feature vectors are sparse: [0.         0.         0.         ... 0.         0.         0.50467087]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- As you can see the representations are sparse and contain `2 * lim_unigram + 1` features."
      ],
      "metadata": {
        "id": "9lZotdd8pXZP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Now the features are ready, we can create the datasets we are going to use for the training and testing:"
      ],
      "metadata": {
        "id": "JJOSPAJHpl7x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "train_size = len(raw_train.stances)\n",
        "dev_size = len(raw_dev.stances)\n",
        "\n",
        "train_labels = [stance_to_int[s] for s in raw_train.stances]\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_features, train_labels))\n",
        "train_dataset = train_dataset.shuffle(train_size)\n",
        "train_dataset = train_dataset.batch(batch_size)\n",
        "train_dataset = train_dataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "dev_labels = [stance_to_int[s] for s in raw_dev.stances]\n",
        "dev_dataset = tf.data.Dataset.from_tensor_slices((dev_features, dev_labels))\n",
        "dev_dataset = dev_dataset.batch(batch_size)\n",
        "dev_dataset = dev_dataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "test_labels = [stance_to_int[s] for s in raw_test.stances]\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_features, test_labels))\n",
        "test_dataset = test_dataset.batch(batch_size).cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "Zq4UVD95oJlu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Let's see a batch from the training dataset:"
      ],
      "metadata": {
        "id": "9PsPUdpNrNcB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch, labels = next(iter(train_dataset))\n",
        "print(f'shape of the batch is: {batch.shape}')\n",
        "print(f'batch instances: {batch.numpy()}')\n",
        "print(f'batch labels: {labels.numpy()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9GX_7GtTL9d",
        "outputId": "3587ff8d-9435-4427-e1cc-51226ebaa4fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of the batch is: (512, 8001)\n",
            "batch instances: [[0.         0.         0.         ... 0.         0.         0.13691706]\n",
            " [0.         0.         0.         ... 0.         0.         0.57642169]\n",
            " [0.         0.         0.         ... 0.         0.         0.10792191]\n",
            " ...\n",
            " [0.         0.         0.         ... 0.         0.         0.2458291 ]\n",
            " [0.         0.         0.         ... 0.         0.         0.08743462]\n",
            " [0.         0.         0.         ... 0.         0.         0.04405263]]\n",
            "batch labels: [0 0 3 3 3 1 3 2 3 3 3 1 3 1 0 0 3 3 0 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 1 3 3\n",
            " 0 3 2 0 1 1 0 3 3 3 0 3 3 0 1 3 0 0 1 3 2 3 3 0 3 1 3 3 2 2 3 3 1 1 0 3 1\n",
            " 3 3 2 2 3 0 3 3 3 3 3 3 3 0 2 3 0 0 3 3 1 3 3 3 3 3 0 3 0 3 2 3 3 0 3 2 0\n",
            " 0 3 3 3 0 3 3 3 1 2 3 0 3 3 0 3 0 1 2 3 2 3 0 2 3 0 2 3 3 0 3 3 3 0 2 3 1\n",
            " 0 0 3 3 0 0 3 3 2 0 3 3 3 3 3 1 3 0 1 1 3 3 3 3 0 0 3 1 3 3 2 0 0 0 3 1 0\n",
            " 2 1 1 3 0 0 3 3 3 3 0 3 1 2 3 1 3 3 1 3 0 0 2 3 0 3 3 0 3 3 2 0 0 0 3 3 3\n",
            " 2 3 0 3 3 3 3 3 3 0 0 1 3 3 3 1 3 3 0 3 2 3 3 0 1 1 3 3 3 3 3 3 0 3 1 2 3\n",
            " 3 3 0 0 3 0 0 0 3 3 0 3 3 3 3 2 0 3 0 3 1 0 3 3 0 0 3 3 3 0 0 3 2 0 3 0 0\n",
            " 3 3 3 1 3 0 3 3 3 2 3 3 3 0 0 0 0 0 3 0 0 3 2 3 0 1 1 1 1 3 3 3 3 3 3 0 0\n",
            " 0 3 0 3 3 0 3 0 1 1 3 3 3 2 1 2 0 2 3 3 3 2 0 3 3 2 3 3 0 0 1 2 3 2 2 2 3\n",
            " 3 3 0 0 0 3 1 3 3 0 2 1 1 3 3 3 3 3 1 0 3 0 0 3 2 0 3 3 3 3 2 0 3 3 0 0 0\n",
            " 3 0 3 3 3 0 3 3 0 0 1 2 3 3 3 3 1 1 0 2 0 1 3 3 0 1 1 3 3 3 3 2 3 3 3 3 1\n",
            " 3 3 0 0 0 3 2 3 3 0 0 3 3 3 0 3 2 3 3 3 0 2 3 3 3 0 0 3 3 3 1 3 3 3 0 3 2\n",
            " 0 0 3 1 0 3 3 0 3 3 3 3 0 0 1 3 0 3 0 3 3 0 3 3 3 1 3 3 1 3 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "RruT-NIyo8OB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Now the datasets are ready, we can work on the model:"
      ],
      "metadata": {
        "id": "1fQMLeI1r8GG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(lr):\n",
        "  inputs = tf.keras.Input(shape=(2*lim_unigram+1,), dtype=tf.float32)\n",
        "  outputs = tf.keras.layers.Dense(4)(inputs)\n",
        "  model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "  model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "5qrg-7Afufs4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plotting_model = create_model(lr=0.)\n",
        "tf.keras.utils.plot_model(plotting_model, show_shapes=True, dpi=80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "UZUmJxeFu0E_",
        "outputId": "590557b5-1b4b-42bb-b66e-74cf7bbe45aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plotting_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "pnc5o7ybu62z",
        "outputId": "708c906e-d380-46ec-aee0-97fbed873c8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8001\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   │          \u001b[38;5;34m32,008\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8001</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">32,008</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m32,008\u001b[0m (125.03 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">32,008</span> (125.03 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m32,008\u001b[0m (125.03 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">32,008</span> (125.03 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training & Evaluation"
      ],
      "metadata": {
        "id": "iO4KIF4LpbXR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reps = 5\n",
        "lr = 6e-2\n",
        "epochs = 100\n",
        "patience = 3\n",
        "\n",
        "histories = []\n",
        "val_accuracy, val_f1score, val_mf1score = [], [], []\n",
        "test_accuracy, test_f1score, test_mf1score = [], [], []\n",
        "for _ in range(reps):\n",
        "  model = create_model(lr)\n",
        "\n",
        "  callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=patience)]\n",
        "  history = model.fit(\n",
        "      x=train_dataset,\n",
        "      validation_data=dev_dataset,\n",
        "      epochs=epochs,\n",
        "      callbacks=callbacks)\n",
        "  histories.append(history)\n",
        "\n",
        "  _, accuracy, f1score, mf1score = evaluate(model, dev_dataset, dev_labels)\n",
        "  val_accuracy.append(accuracy)\n",
        "  val_f1score.append(f1score)\n",
        "  val_mf1score.append(mf1score)\n",
        "\n",
        "  _, accuracy, f1score, mf1score = evaluate(model, test_dataset, test_labels)\n",
        "  test_accuracy.append(accuracy)\n",
        "  test_f1score.append(f1score)\n",
        "  test_mf1score.append(mf1score)"
      ],
      "metadata": {
        "id": "YHaAyk5Xo72h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fce55766-c27d-48f1-f416-4e90e64074ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.4570 - loss: 1.1355 - val_accuracy: 0.6362 - val_loss: 1.0476\n",
            "Epoch 2/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8098 - loss: 0.5604 - val_accuracy: 0.7118 - val_loss: 0.8074\n",
            "Epoch 3/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8966 - loss: 0.3577 - val_accuracy: 0.7417 - val_loss: 0.7620\n",
            "Epoch 4/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9247 - loss: 0.2656 - val_accuracy: 0.7575 - val_loss: 0.7530\n",
            "Epoch 5/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9418 - loss: 0.2080 - val_accuracy: 0.7733 - val_loss: 0.7500\n",
            "Epoch 6/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9585 - loss: 0.1704 - val_accuracy: 0.7733 - val_loss: 0.7386\n",
            "Epoch 7/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9675 - loss: 0.1423 - val_accuracy: 0.7786 - val_loss: 0.7383\n",
            "Epoch 8/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9715 - loss: 0.1217 - val_accuracy: 0.7768 - val_loss: 0.7472\n",
            "Epoch 9/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9742 - loss: 0.1064 - val_accuracy: 0.7786 - val_loss: 0.7576\n",
            "Epoch 10/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9760 - loss: 0.0949 - val_accuracy: 0.7821 - val_loss: 0.7641\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7870 - loss: 0.7429\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8465 - loss: 0.6251\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "Epoch 1/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.4579 - loss: 1.1349 - val_accuracy: 0.6327 - val_loss: 1.0484\n",
            "Epoch 2/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8097 - loss: 0.5610 - val_accuracy: 0.7118 - val_loss: 0.8080\n",
            "Epoch 3/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8982 - loss: 0.3577 - val_accuracy: 0.7381 - val_loss: 0.7626\n",
            "Epoch 4/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9251 - loss: 0.2658 - val_accuracy: 0.7557 - val_loss: 0.7529\n",
            "Epoch 5/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9426 - loss: 0.2080 - val_accuracy: 0.7715 - val_loss: 0.7504\n",
            "Epoch 6/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9596 - loss: 0.1705 - val_accuracy: 0.7750 - val_loss: 0.7389\n",
            "Epoch 7/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9682 - loss: 0.1423 - val_accuracy: 0.7786 - val_loss: 0.7384\n",
            "Epoch 8/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9717 - loss: 0.1217 - val_accuracy: 0.7786 - val_loss: 0.7471\n",
            "Epoch 9/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9742 - loss: 0.1065 - val_accuracy: 0.7786 - val_loss: 0.7577\n",
            "Epoch 10/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9760 - loss: 0.0949 - val_accuracy: 0.7821 - val_loss: 0.7643\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7870 - loss: 0.7431\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8476 - loss: 0.6253\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Epoch 1/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.4642 - loss: 1.1352 - val_accuracy: 0.6344 - val_loss: 1.0468\n",
            "Epoch 2/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8110 - loss: 0.5602 - val_accuracy: 0.7100 - val_loss: 0.8077\n",
            "Epoch 3/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.8975 - loss: 0.3575 - val_accuracy: 0.7381 - val_loss: 0.7627\n",
            "Epoch 4/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9240 - loss: 0.2654 - val_accuracy: 0.7522 - val_loss: 0.7529\n",
            "Epoch 5/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.9423 - loss: 0.2079 - val_accuracy: 0.7715 - val_loss: 0.7498\n",
            "Epoch 6/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9592 - loss: 0.1703 - val_accuracy: 0.7750 - val_loss: 0.7386\n",
            "Epoch 7/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9682 - loss: 0.1422 - val_accuracy: 0.7786 - val_loss: 0.7383\n",
            "Epoch 8/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9711 - loss: 0.1216 - val_accuracy: 0.7821 - val_loss: 0.7470\n",
            "Epoch 9/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9742 - loss: 0.1064 - val_accuracy: 0.7821 - val_loss: 0.7575\n",
            "Epoch 10/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9760 - loss: 0.0948 - val_accuracy: 0.7856 - val_loss: 0.7640\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7907 - loss: 0.7426 \n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8499 - loss: 0.6251\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
            "Epoch 1/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.4651 - loss: 1.1347 - val_accuracy: 0.6344 - val_loss: 1.0483\n",
            "Epoch 2/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8103 - loss: 0.5600 - val_accuracy: 0.7118 - val_loss: 0.8090\n",
            "Epoch 3/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8978 - loss: 0.3574 - val_accuracy: 0.7417 - val_loss: 0.7639\n",
            "Epoch 4/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9241 - loss: 0.2653 - val_accuracy: 0.7504 - val_loss: 0.7545\n",
            "Epoch 5/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9429 - loss: 0.2079 - val_accuracy: 0.7715 - val_loss: 0.7514\n",
            "Epoch 6/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9595 - loss: 0.1703 - val_accuracy: 0.7733 - val_loss: 0.7401\n",
            "Epoch 7/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9675 - loss: 0.1422 - val_accuracy: 0.7786 - val_loss: 0.7398\n",
            "Epoch 8/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9715 - loss: 0.1216 - val_accuracy: 0.7786 - val_loss: 0.7487\n",
            "Epoch 9/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9742 - loss: 0.1063 - val_accuracy: 0.7768 - val_loss: 0.7591\n",
            "Epoch 10/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9760 - loss: 0.0948 - val_accuracy: 0.7786 - val_loss: 0.7656\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7840 - loss: 0.7445\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8465 - loss: 0.6263\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
            "Epoch 1/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.4682 - loss: 1.1341 - val_accuracy: 0.6362 - val_loss: 1.0475\n",
            "Epoch 2/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8112 - loss: 0.5596 - val_accuracy: 0.7118 - val_loss: 0.8078\n",
            "Epoch 3/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8980 - loss: 0.3574 - val_accuracy: 0.7364 - val_loss: 0.7630\n",
            "Epoch 4/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9253 - loss: 0.2653 - val_accuracy: 0.7540 - val_loss: 0.7537\n",
            "Epoch 5/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9422 - loss: 0.2079 - val_accuracy: 0.7698 - val_loss: 0.7506\n",
            "Epoch 6/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9601 - loss: 0.1703 - val_accuracy: 0.7750 - val_loss: 0.7394\n",
            "Epoch 7/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9682 - loss: 0.1422 - val_accuracy: 0.7803 - val_loss: 0.7390\n",
            "Epoch 8/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9718 - loss: 0.1216 - val_accuracy: 0.7786 - val_loss: 0.7479\n",
            "Epoch 9/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9742 - loss: 0.1063 - val_accuracy: 0.7786 - val_loss: 0.7584\n",
            "Epoch 10/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9760 - loss: 0.0948 - val_accuracy: 0.7786 - val_loss: 0.7649\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7834 - loss: 0.7437\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8459 - loss: 0.6265\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Overfitting Analysis**  \n",
        "The gap between training and validation performance indicates that the model is overfitting the training data. Several factors contribute to this issue:\n",
        "1. **Insufficient Data**: The relatively small training dataset of 2848 instances is insufficient for the model to learn the intricate nuances of the task, particularly given its inherent complexity.\n",
        "2. **Task Complexity:** The 'disagree' and 'discuss' classes pose significant challenges due to their subtle distinctions. While 'unrelated' and 'agree' classes can often be identified through simple textual similarity, 'disagree' and 'discuss' require deeper semantic understanding and the ability to detect complex linguistic cues:\n",
        "   - **Discuss class:** Discussing involves giving more details and different viewpoints.\n",
        "   - **Disagree class:** Disagreement could involve simple negation terms or more complex negations like changing dates, quantities, or introducing opposing concepts (e.g. Sky is Blue vs. Sky is Black).\n",
        "\n",
        "3. **Annotation Errors:** Manual inspection has revealed a non-negligible number of misannotations, further complicating the learning process.\n",
        "4. **Language Challenges:** Arabic, the language of the dataset, presents additional complexities due to its rich morphology and diverse dialects.\n",
        "5. **Class Imbalance:** The 'unrelated' class significantly outnumbers the other classes. Additionally, the 'disagree' and 'discuss' classes are underrepresented compared to the 'agree' and 'unrelated' classes. The relative lower representations of the 'discuss' and 'disagree' classes across the three sets exacerbates the classification challenge.\n",
        "\n",
        "![image not found](tab_arastance.png)\n",
        "\n",
        "**Mitigating Overfitting**  \n",
        "While regularization techniques and early stopping may have limited effectiveness, addressing the underlying data limitations is crucial:\n",
        "1. **Data Augmentation:** Explore techniques like back-translation, synonym replacement, and text generation to artificially expand the dataset.\n",
        "2. **Transfer Learning:** Leverage pre-trained language models to incorporate prior knowledge and improve generalization.\n",
        "3. **Ensemble Methods:** Combine multiple models to reduce variance and improve overall performance.\n",
        "\n"
      ],
      "metadata": {
        "id": "U6ajpmffwEYP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Results"
      ],
      "metadata": {
        "id": "svj2dx55pMch"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Validation Resutls:\")\n",
        "print(\"=====================\")\n",
        "print(f\"Mean Accuracy: {np.mean(val_accuracy):.3f}\")\n",
        "agree, disagree, discuss, unrelated = np.mean(val_f1score, axis=0)\n",
        "print(\"Mean Per Class F1 scores:\")\n",
        "print(f\"Agree   : {agree:.3f}\")\n",
        "print(f\"Disagree: {disagree:.3f}\")\n",
        "print(f\"Discuss : {discuss:.3f}\")\n",
        "print(f\"Unrelated: {unrelated:.3f}\")\n",
        "print(f\"Mean Macro F1 scores: {np.mean(val_mf1score):.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8L3hegPpg0J",
        "outputId": "e8db160b-0377-452b-cf42-bbaf6f005b8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Resutls:\n",
            "=====================\n",
            "Mean Accuracy: 0.781\n",
            "Mean Per Class F1 scores:\n",
            "Agree   : 0.760\n",
            "Disagree: 0.738\n",
            "Discuss : 0.513\n",
            "Unrelated: 0.846\n",
            "Mean Macro F1 scores: 0.714\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Testing Resutls:\")\n",
        "print(\"=====================\")\n",
        "print(f\"Mean Accuracy: {np.mean(test_accuracy):.3f}\")\n",
        "agree, disagree, discuss, unrelated = np.mean(test_f1score, axis=0)\n",
        "print(\"Mean Per Class F1 scores:\")\n",
        "print(f\"Agree   : {agree:.3f}\")\n",
        "print(f\"Disagree: {disagree:.3f}\")\n",
        "print(f\"Discuss : {discuss:.3f}\")\n",
        "print(f\"Unrelated: {unrelated:.3f}\")\n",
        "print(f\"Mean Macro F1 scores: {np.mean(test_mf1score):.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXyHHd39pj3n",
        "outputId": "1e0ef212-e1cf-4711-b0a6-0ae7caf54929"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing Resutls:\n",
            "=====================\n",
            "Mean Accuracy: 0.824\n",
            "Mean Per Class F1 scores:\n",
            "Agree   : 0.818\n",
            "Disagree: 0.767\n",
            "Discuss : 0.425\n",
            "Unrelated: 0.886\n",
            "Mean Macro F1 scores: 0.724\n"
          ]
        }
      ]
    }
  ]
}